{
    "NodeDetails": {
        "SQL": "WITH node_slice AS\n(\n  SELECT node,\n         COUNT(1) AS slice_count\n  FROM stv_slices\n  GROUP BY node\n),\nnode_storage_utilization AS\n(\n  SELECT node::text AS node,\n         (1.0 * used / capacity)::NUMERIC(8,4) * 100 AS storage_utilization_pct,\n         1.0 * capacity/1000 AS storage_capacity_gb,\n         1.0 * used/1000 AS storage_used_gb\n  FROM stv_node_storage_capacity\n)\nSELECT CASE\n         WHEN capacity = 190633 AND NOT is_nvme THEN 'dc1.large'\n         WHEN capacity = 380319 THEN 'dc1.8xlarge'\n         WHEN capacity = 190633 AND is_nvme THEN 'dc2.large'\n         WHEN capacity = 760956 THEN 'dc2.8xlarge'\n         WHEN capacity = 726296 THEN 'dc2.8xlarge'\n         WHEN capacity = 952455 THEN 'ds2.xlarge'\n         WHEN capacity = 945026 THEN 'ds2.8xlarge'\n         WHEN capacity = 954367 AND part_count = 1 THEN 'ra3.xlplus'\n         WHEN capacity = 3339176 AND part_count = 1 THEN 'ra3.4xlarge'\n         WHEN capacity = 3339176 AND part_count = 4 THEN 'ra3.16xlarge'\n         ELSE 'unknown'\n       END AS node_type,\n       s.node,\n       slice_count,\n       storage_utilization_pct,\n       storage_capacity_gb,\n       storage_used_gb\nFROM (SELECT p.host AS node,\n             p.capacity,\n             p.mount LIKE '/dev/nvme%' AS is_nvme,\n             COUNT(1) AS part_count\n      FROM stv_partitions p\n      WHERE p.host = p.owner\n      GROUP BY 1,\n               2,\n               3) AS s\n  INNER JOIN node_slice n ON (s.node = n.node)\n  INNER JOIN node_storage_utilization ns ON (s.node = ns.node)\nORDER by 2;"
    },
    "WLMConfig": {
        "SQL": "SELECT c.wlm_mode,\n       scc.service_class::text AS service_class_id,\n       CASE\n         WHEN scc.service_class BETWEEN 1 AND 4 THEN 'System'\n         WHEN scc.service_class = 5 THEN 'Superuser'\n         WHEN scc.service_class BETWEEN 6 AND 13 THEN 'Manual WLM'\n         WHEN scc.service_class = 14 THEN 'SQA'\n         WHEN scc.service_class = 15 THEN 'Redshift Maintenance'\n         WHEN scc.service_class BETWEEN 100 AND 107 THEN 'Auto WLM'\n       END AS service_class_category,\n       trim(scc.name) AS queue_name,\n       CASE\n         WHEN scc.num_query_tasks = -1 THEN 'auto'\n         ELSE scc.num_query_tasks::text\n       END AS slots,\n       CASE\n         WHEN scc.query_working_mem = -1 THEN 'auto'\n         ELSE scc.query_working_mem::text\n       END AS query_working_memory_mb_per_slot,\n       nvl(cast(ROUND(((scc.num_query_tasks*scc.query_working_mem)::NUMERIC/ mem.total_memory_mb::NUMERIC)*100,0)::NUMERIC(38,4) as varchar(12)),'auto') cluster_memory_pct,\n       scc.max_execution_time AS query_timeout,\n       trim(scc.concurrency_scaling) AS concurrency_scaling,\n       trim(scc.query_priority) AS queue_priority,\n       nvl(qc.qmr_rule_count,0) AS qmr_rule_count,\n       CASE\n         WHEN qmr.qmr_rule IS NOT NULL THEN 'Y'\n         ELSE 'N'\n       END AS is_queue_evictable,\n       LISTAGG(DISTINCT TRIM(qmr.qmr_rule),',') within group(ORDER BY rule_name) qmr_rule,\n       LISTAGG(TRIM(cnd.condition),', ') condition\nFROM stv_wlm_service_class_config scc\n  INNER JOIN stv_wlm_classification_config cnd ON scc.service_class = cnd.action_service_class\n  CROSS JOIN (SELECT CASE\n                       WHEN COUNT(1) \u003E 0 THEN 'auto'\n                       ELSE 'manual'\n                     END AS wlm_mode\n              FROM stv_wlm_service_class_config\n              WHERE service_class \u003E= 100) c\n  CROSS JOIN (SELECT SUM(num_query_tasks*query_working_mem) AS total_memory_mb\n              FROM stv_wlm_service_class_config\n              WHERE service_class BETWEEN 6 AND 13) mem\n  LEFT OUTER JOIN (SELECT service_class,\n                          COUNT(DISTINCT rule_name) AS qmr_rule_count\n                   FROM stv_wlm_qmr_config\n                   GROUP BY service_class) qc ON (scc.service_class = qc.service_class)\n  LEFT OUTER JOIN (SELECT service_class,\n                          rule_name,\n                          rule_name || ':' || '[' || action || '] ' || metric_name || metric_operator || CAST(metric_value AS VARCHAR(256)) qmr_rule\n                   FROM stv_wlm_qmr_config) qmr ON scc.service_class = qmr.service_class\nWHERE scc.service_class \u003E 4\nGROUP BY 1,\n         2,\n         3,\n         4,\n         5,\n         6,\n         7,\n         8,\n         9,\n         10,\n         11,\n         12\nORDER BY 2 ASC;"
    },
    "WLMandCommit": {
        "SQL": "SELECT IQ.*,\n       (IQ.wlm_queue_time_ms/ IQ.wlm_start_commit_time_ms)*100.0::numeric(6,2) AS pct_wlm_queue_time,\n       (IQ.exec_only_time_ms/ IQ.wlm_start_commit_time_ms)*100.0::numeric(6,2) AS pct_exec_only_time,\n       (IQ.commit_queue_time_ms/ IQ.wlm_start_commit_time_ms)*100.0::numeric(6,2) pct_commit_queue_time,\n       (IQ.commit_time_ms/ IQ.wlm_start_commit_time_ms)*100.0::numeric(6,2) pct_commit_time\nFROM (SELECT TRUNC(b.starttime) AS DAY,\n             d.service_class,\n             rtrim(s.name) as queue_name,\n             c.node,\n             COUNT(DISTINCT c.xid) AS count_commit_xid,\n             SUM(datediff ('microsec',d.service_class_start_time,c.endtime)*0.001)::numeric(38,4) AS wlm_start_commit_time_ms,\n             SUM(datediff ('microsec',d.queue_start_time,d.queue_end_time)*0.001)::numeric(38,4) AS wlm_queue_time_ms,\n             SUM(datediff ('microsec',b.starttime,b.endtime)*0.001)::numeric(38,4) AS exec_only_time_ms,\n             SUM(datediff ('microsec',c.startwork,c.endtime)*0.001)::numeric(38,4) commit_time_ms,\n             SUM(datediff ('microsec',DECODE(c.startqueue,'2000-01-01 00:00:00',c.startwork,c.startqueue),c.startwork)*0.001)::numeric(38,4) commit_queue_time_ms\n      FROM stl_query b,\n           stl_commit_stats c,\n           stl_wlm_query d,\n           stv_wlm_service_class_config s\n      WHERE b.xid = c.xid\n      AND   b.query = d.query\n      AND   c.xid \u003E 0\n      AND d.service_class = s.service_class\n      GROUP BY 1,2,3,4\n      ORDER BY 1,2,3,4) IQ;"
    },
    "QueueHealth": {
        "SQL": "with workload as\n(\nselect trim(sq.\"database\") as dbname\n      ,case \n\t     when sq.concurrency_scaling_status = 1 then 'burst'\t        \n\t\t\t else 'main' end as concurrency_scaling_status \n      ,case \n       when sl.source_query is not null then 'result_cache'       \n\t\t\t else rtrim(swsc.name) end as queue_name \n\t\t\t,swq.service_class \n      ,case\n       when swq.service_class between 1 and 4 then 'System'\n       when swq.service_class = 5 then 'Superuser'\n       when swq.service_class between 6 and 13 then'Manual WLM queues'\n       when swq.service_class = 14 then 'SQA'\n       when swq.service_class = 15 then 'Redshift Maintenance'\n       when swq.service_class between 100 and 107 then 'Auto WLM'\n       end as service_class_category \t  \n      ,sq.query as query_id\n      ,case \n         when regexp_instr(sq.querytxt, '(padb_|pg_internal)'             ) then 'OTHER'\n         when regexp_instr(sq.querytxt, '([uU][nN][dD][oO][iI][nN][gG]) ' ) then 'SYSTEM'\n         when regexp_instr (sq.querytxt,'([aA][uU][tT][oO][mM][vV])'      ) then 'AUTOMV'\n         when regexp_instr(sq.querytxt, '[uU][nN][lL][oO][aA][dD]'        ) then 'UNLOAD'\n         when regexp_instr(sq.querytxt, '[cC][uU][rR][sS][oO][rR] '       ) then 'CURSOR'\n         when regexp_instr(sq.querytxt, '[fF][eE][tT][cC][hH] '           ) then 'CURSOR'\n         WHEN regexp_instr (sq.querytxt,'[cC][rR][eE][aA][tT][eE] '       ) then 'CTAS'\n         when regexp_instr(sq.querytxt, '[dD][eE][lL][eE][tT][eE] '       ) then 'DELETE'\n         when regexp_instr(sq.querytxt, '[uU][pP][dD][aA][tT][eE] '       ) then 'UPDATE'\n         when regexp_instr(sq.querytxt, '[iI][nN][sS][eE][rR][tT] '       ) then 'INSERT'\n         when regexp_instr(sq.querytxt, '[vV][aA][cC][uU][uU][mM][ :]'    ) then 'VACUUM'\n         when regexp_instr(sq.querytxt, '[aA][nN][aA][lL][yY][zZ][eE] '   ) then 'ANALYZE'\t\t \n         when regexp_instr(sq.querytxt, '[sS][eE][lL][eE][cC][tT] '       ) then 'SELECT'\n         when regexp_instr(sq.querytxt, '[cC][oO][pP][yY] '               ) then 'COPY'\n         else 'OTHER' \n       end as query_type \n      ,date_trunc('hour',sq.starttime) as workload_exec_hour\n      ,nvl(swq.est_peak_mem/1024.0/1024.0/1024.0,0.0) as est_peak_mem_gb\n      ,decode(swq.final_state, 'Completed',decode(swr.action, 'abort',0,decode(sq.aborted,0,1,0)),'Evicted',0,null,decode(sq.aborted,0,1,0)::int) as is_completed\n      ,decode(swq.final_state, 'Completed',decode(swr.action, 'abort',1,0),'Evicted',1,null,0) as is_evicted_aborted\n      ,decode(swq.final_state, 'Completed',decode(swr.action, 'abort',0,decode(sq.aborted,1,1,0)),'Evicted',0,null,decode(sq.aborted,1,1,0)::int) as is_user_aborted\n\t    ,case when sl.from_sp_call is not null then 1 else 0 end as from_sp_call\n\t    ,case when alrt.num_events is null then 0 else alrt.num_events end as alerts\n\t    ,case when dsk.num_diskbased \u003E 0 then 1 else 0 end as is_query_diskbased\n\t    ,nvl(c.num_compile_segments,0) as num_compile_segments\n      ,cast(case when sqms.query_queue_time is null then 0 else sqms.query_queue_time end as decimal(26,6)) as query_queue_time_secs\n\t    ,nvl(c.max_compile_time_secs,0) as max_compile_time_secs\n\t    ,sl.starttime\n\t    ,sl.endtime\n\t    ,sl.elapsed\n      ,cast(sl.elapsed * 0.000001 as decimal(26,6)) as query_execution_time_secs\t\n      ,sl.elapsed * 0.000001 - nvl(c.max_compile_time_secs,0)  - nvl(sqms.query_queue_time,0) as actual_execution_time_secs\t  \n      ,case when sqms.query_temp_blocks_to_disk is null then 0 else sqms.query_temp_blocks_to_disk end as query_temp_blocks_to_disk_mb\n      ,cast(case when sqms.query_cpu_time is null then 0 else sqms.query_cpu_time end as decimal(26,6)) as query_cpu_time_secs \n\t    ,nvl(sqms.scan_row_count,0) as scan_row_count\n      ,nvl(sqms.return_row_count,0) as return_row_count\n      ,nvl(sqms.nested_loop_join_row_count,0) as nested_loop_join_row_count\n      ,nvl(uc.usage_limit_count,0) as cs_usage_limit_count\n  from stl_query sq\n  inner join svl_qlog sl on (sl.userid = sq.userid and sl.query = sq.query)\n  left outer join svl_query_metrics_summary sqms on (sqms.userid = sq.userid and sqms.query = sq.query)\t\t\t\t\t\n  left outer join stl_wlm_query swq on (sq.userid = swq.userid and sq.query = swq.query)\n  left outer join stl_wlm_rule_action swr on (sq.userid = swr.userid and sq.query = swr.query and swq.service_class = swr.service_class)\n  left outer join stv_wlm_service_class_config swsc on (swsc.service_class = swq.service_class)\n  left outer join (select sae.query\n                         ,cast(1 as integer) as num_events\n                     from svcs_alert_event_log sae\n                   group by sae.query) as alrt on (alrt.query = sq.query)  \n  left outer join (select sqs.userid\n                         ,sqs.query\n                         ,1 as num_diskbased\n                     from svcs_query_summary sqs    \n                    where sqs.is_diskbased = 't'\n                   group by sqs.userid, sqs.query\n                   ) as dsk on (dsk.userid = sq.userid and dsk.query = sq.query)  \n  left outer join (select userid, xid,  pid, query\n                         ,max(datediff(ms, starttime, endtime)*1.0/1000) as max_compile_time_secs\n\t                     ,sum(compile) as num_compile_segments\n                     from svcs_compile\n                   group by userid, xid,  pid, query\n                  ) c on (c.userid = sq.userid and c.xid = sq.xid and c.pid = sq.pid and c.query = sq.query)                 \n  left outer join (select query,xid,pid\n                          ,count(1) as usage_limit_count\n                      from stl_usage_control \n                     where feature_type = 'CONCURRENCY_SCALING'\n                   group by query, xid, pid) uc on (uc.xid = sq.xid and uc.pid = sq.pid and uc.query = sq.query)                  \t   \n  where sq.userid \u003C\u003E 1 \n    and sq.querytxt not like 'padb_fetch_sample%'\n    and sq.starttime \u003E= dateadd(day,-7,current_date)\n)\nselect workload_exec_hour\n      ,service_class_category\n      ,service_class\n      ,queue_name\n      ,concurrency_scaling_status\n      ,dbname\n      ,query_type\n      ,sum(is_completed) + sum(is_user_aborted) + sum(is_evicted_aborted) as total_query_count\n      ,sum(is_completed) as completed_query_count\n      ,sum(is_user_aborted) as user_aborted_count\n      ,sum(is_evicted_aborted) as wlm_evicted_count\n      ,round(sum(est_peak_mem_gb),4) as total_est_peak_mem_gb\n      ,sum(is_query_diskbased) as total_disk_spill_count\n      ,sum(num_compile_segments) as total_compile_count\n      ,round(sum(query_temp_blocks_to_disk_mb/1024.0),4) as total_disk_spill_gb\n      ,sum(alerts) as total_query_alert_count\n      ,sum(from_sp_call) as total_called_proc_count\n\t  ,avg(query_execution_time_secs) as avg_query_execution_time_secs\n\t  ,max(query_execution_time_secs) as max_query_execution_time_secs\n      ,sum(query_execution_time_secs) as total_query_execution_time_secs\n\t  ,avg(max_compile_time_secs) as avg_compile_time_secs\n\t  ,max(max_compile_time_secs) as max_compile_time_secs\n      ,sum(max_compile_time_secs) as total_compile_time_secs\n\t  ,avg(query_queue_time_secs) as avg_query_queue_time_secs\n\t  ,max(query_queue_time_secs) as max_query_queue_time_secs\n      ,sum(query_queue_time_secs) as total_query_queue_time_secs\n\t  ,avg(actual_execution_time_secs) as avg_actual_execution_time_secs\n      ,sum(actual_execution_time_secs) as total_actual_execution_time_secs\n      ,sum(query_cpu_time_secs) as total_query_cpu_time_secs\n      ,sum(cs_usage_limit_count) as total_cs_usage_limit_count\n      ,sum(scan_row_count) as total_scan_row_count\n      ,sum(return_row_count) as total_return_row_count\n      ,sum(nested_loop_join_row_count) as total_nl_join_row_count\n  from workload\n  group by 1,2,3,4,5,6,7\n  order by 1,2,3,4,5,6,7;"
    },
    "UsagePattern": {
        "SQL": "WITH workload_profile AS\n(\n  SELECT trim(t.\"database\") AS dbname,\n         s.statement_type,\n         CAST(CASE \n              WHEN regexp_instr (s.statement_text,'(padb_|pg_internal)'              ) THEN 'SYSTEM' \n              WHEN regexp_instr (s.statement_text,'([uU][nN][dD][oO][iI][nN][gG]) '  ) THEN 'SYSTEM' \n              WHEN regexp_instr (s.statement_text,'([aA][uU][tT][oO][mM][vV])'       ) THEN 'AUTOMV' \n              WHEN regexp_instr (s.statement_text,'[uU][nN][lL][oO][aA][dD]'         ) THEN 'UNLOAD' \n              WHEN regexp_instr (s.statement_text,'[cC][uU][rR][sS][oO][rR] '        ) THEN 'CURSOR' \n              WHEN regexp_instr (s.statement_text,'[cC][rR][eE][aA][tT][eE] '        ) THEN 'DDL' \n              WHEN regexp_instr (s.statement_text,'[aA][lL][tT][eE][rR] '            ) THEN 'DDL' \n              WHEN regexp_instr (s.statement_text,'[dD][rR][oO][pP] '                ) THEN 'DDL' \n              WHEN regexp_instr (s.statement_text,'[tT][rR][uU][nN][cC][aA][tT][eE] ') THEN 'DDL' \n              WHEN regexp_instr (s.statement_text,'[cC][aA][lL][lL] '                ) THEN 'CALL_PROCEDURE' \n              WHEN regexp_instr (s.statement_text,'[gG][rR][aA][nN][tT] '            ) THEN 'DCL' \n              WHEN regexp_instr (s.statement_text,'[rR][eE][vV][oO][kK][eE] '        ) THEN 'DCL' \n              WHEN regexp_instr (s.statement_text,'[fF][eE][tT][cC][hH] '            ) THEN 'CURSOR' \n              WHEN regexp_instr (s.statement_text,'[dD][eE][lL][eE][tT][eE] '        ) THEN 'DELETE'\n              WHEN regexp_instr (s.statement_text,'[uU][pP][dD][aA][tT][eE] '        ) THEN 'UPDATE' \n              WHEN regexp_instr (s.statement_text,'[iI][nN][sS][eE][rR][tT] '        ) THEN 'INSERT' \n              WHEN regexp_instr (s.statement_text,'[vV][aA][cC][uU][uU][mM][ :]'     ) THEN 'VACUUM' \n              WHEN regexp_instr (s.statement_text,'[aA][nN][aA][lL][yY][zZ][eE] '    ) THEN 'ANALYZE' \n              WHEN regexp_instr (s.statement_text,'[sS][eE][lL][eE][cC][tT] '        ) THEN 'SELECT' \n              WHEN regexp_instr (s.statement_text,'[cC][oO][pP][yY] '                ) THEN 'COPY' \n              ELSE 'OTHER' \n              END AS VARCHAR(32)) AS query_type,\n         DATEPART(HOUR,t.starttime) query_hour,\n\t\t t.starttime::DATE as query_date,\n         ROUND(SUM(duration_secs),1) query_duration_secs,\n         COUNT(*) query_count\n  FROM (SELECT s.userid,\n               s.type AS statement_type,\n               s.xid,\n               s.pid,\n               DATEDIFF(milliseconds,starttime,endtime)::NUMERIC(38,4) / 1000 AS duration_secs,\n               CAST(REPLACE(rtrim(s.text),'\\n','') AS VARCHAR(800)) AS statement_text\n        FROM svl_statementtext s\n        WHERE s.sequence = 0\n        AND   s.starttime \u003E= DATEADD(DAY,-7,CURRENT_DATE)\n       ) s\n    LEFT OUTER JOIN stl_query t\n                 ON (s.xid = t.xid\n                AND s.pid = t.pid\n                AND s.userid = t.userid)\n  WHERE s.statement_text NOT LIKE '%volt_tt_%'\n  GROUP BY 1,2,3,4,5\n)\nSELECT wp.dbname,\n       wp.query_date,\n       wp.query_hour,\n       MAX(NVL(CASE WHEN wp.query_type = 'SELECT' THEN query_count ELSE 0 END,0))::bigint AS select_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'SELECT' THEN query_duration_secs ELSE 0 END,0)) AS select_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'CURSOR' THEN query_count ELSE 0 END,0))::bigint AS cursor_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'CURSOR' THEN query_duration_secs ELSE 0 END,0)) AS cursor_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'UNLOAD' THEN query_count ELSE 0 END,0))::bigint AS unload_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'UNLOAD' THEN query_duration_secs ELSE 0 END,0)) AS unload_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'COPY' THEN query_count ELSE 0 END,0))::bigint AS copy_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'COPY' THEN query_duration_secs ELSE 0 END,0)) AS copy_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'INSERT' THEN query_count ELSE 0 END,0))::bigint AS insert_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'INSERT' THEN query_duration_secs ELSE 0 END,0)) AS insert_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'UPDATE' THEN query_count ELSE 0 END,0))::bigint AS update_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'UPDATE' THEN query_duration_secs ELSE 0 END,0)) AS update_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'DELETE' THEN query_count ELSE 0 END,0))::bigint AS delete_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'DELETE' THEN query_duration_secs ELSE 0 END,0)) AS delete_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'VACUUM' THEN query_count ELSE 0 END,0))::bigint AS vacuum_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'VACUUM' THEN query_duration_secs ELSE 0 END,0)) AS vacuum_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'ANALYZE' THEN query_count ELSE 0 END,0))::bigint AS analyze_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'ANALYZE' THEN query_duration_secs ELSE 0 END,0)) AS analyze_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'CALL_PROCEDURE' THEN query_count ELSE 0 END,0))::bigint AS call_proc_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'CALL_PROCEDURE' THEN query_duration_secs ELSE 0 END,0)) AS call_proc_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'DDL' THEN query_count ELSE 0 END,0))::bigint AS ddl_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'DDL' THEN query_duration_secs ELSE 0 END,0)) AS ddl_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'DCL' THEN query_count ELSE 0 END,0))::bigint AS dcl_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'DCL' THEN query_duration_secs ELSE 0 END,0)) AS dcl_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'AUTOMV' THEN query_count ELSE 0 END,0))::bigint AS automv_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'AUTOMV' THEN query_duration_secs ELSE 0 END,0)) AS automv_duration_secs,\n       MAX(NVL(CASE WHEN wp.query_type = 'OTHER' THEN query_count ELSE 0 END,0))::bigint AS other_count,\n       MAX(NVL(CASE WHEN wp.query_type = 'OTHER' THEN query_duration_secs ELSE 0 END,0)) AS other_duration_secs\nFROM workload_profile wp\nWHERE wp.dbname \u003C\u003E 'padb_harvest'\nGROUP BY 1,2,3\nORDER BY 1,2,3;"
    },
    "ConcurrencyScalingUsage": {
        "SQL": "select date_trunc('hour',end_time) as burst_hour\n      ,sum(queries) as query_count\n      ,sum(usage_in_seconds) as burst_usage_in_seconds  \nfrom svcs_concurrency_scaling_usage\ngroup by burst_hour;"
    },
    "TableAlerts": {
        "SQL": "SELECT trim(q.\"database\") as dbname,\n       trim(s.perm_table_name) AS table_name,\n       COALESCE(SUM(ABS(datediff (microsecond,COALESCE(b.starttime,d.starttime,s.starttime),CASE WHEN COALESCE(b.endtime,d.endtime,s.endtime) \u003ECOALESCE(b.starttime,d.starttime,s.starttime) THEN COALESCE(b.endtime,d.endtime,s.endtime) ELSE COALESCE(b.starttime,d.starttime,s.starttime) END)))/ 1000000::NUMERIC(38,4),0) AS alert_seconds,\n       COALESCE(SUM(COALESCE(b.rows,d.rows,s.rows)),0) AS alert_rowcount,\n       trim(split_part (l.event,':',1)) AS alert_event,\n       substring(trim(l.solution),1,200) AS alert_solution,\n       MAX(l.query) AS alert_sample_query,\n       COUNT(DISTINCT l.query) alert_querycount\nFROM stl_alert_event_log AS l\n  LEFT JOIN stl_scan AS s\n         ON s.query = l.query\n        AND s.slice = l.slice\n        AND s.segment = l.segment\n        AND s.userid \u003E 1\n        AND s.perm_table_name NOT IN ('Internal Worktable','S3')\n\t\tAND s.perm_table_name NOT LIKE ('volt_tt%')\n\t\tAND s.perm_table_name NOT LIKE ('mv_tbl__auto_mv%')\t\t\t\n  LEFT JOIN stl_dist AS d\n         ON d.query = l.query\n        AND d.slice = l.slice\n        AND d.segment = l.segment\n        AND d.userid \u003E 1\n  LEFT JOIN stl_bcast AS b\n         ON b.query = l.query\n        AND b.slice = l.slice\n        AND b.segment = l.segment\n        AND b.userid \u003E 1    \n  LEFT JOIN stl_query AS q   \n         ON q.query = l.query\n        AND q.xid = l.xid\n        AND q.userid \u003E 1           \nWHERE l.userid \u003E 1\n  AND trim(s.perm_table_name) IS NOT NULL\n  AND l.event_time \u003E= dateadd(day,- 7,CURRENT_DATE)\nGROUP BY 1,2,5,6\nORDER BY alert_seconds DESC;"
    },
    "TableInfo": {
        "SQL": "SELECT t.\"database\" AS dbname,\n       t.\"schema\" AS namespace,\n       t.\"table\" table_name,\n       t.encoded,\n       t.diststyle,\n       t.sortkey1,\n       t.max_varchar,\n       trim(t.sortkey1_enc) AS sortkey1_enc,\n       t.sortkey_num,\n       t.unsorted,\n       t.stats_off,\n       t.tbl_rows,\n       t.skew_rows,\n       t.estimated_visible_rows,\n       CASE\n         WHEN t.tbl_rows - t.estimated_visible_rows \u003C 0 THEN 0\n         ELSE (t.tbl_rows - t.estimated_visible_rows)\n       END AS num_rows_marked_for_deletion,\n       CASE\n         WHEN t.tbl_rows - t.estimated_visible_rows \u003C 0 THEN 0\n         ELSE (t.tbl_rows - t.estimated_visible_rows) /\n           CASE\n             WHEN nvl (t.tbl_rows,0) = 0 THEN 1\n             ELSE t.tbl_rows\n           END ::NUMERIC(38,4)\n       END AS pct_rows_marked_for_deletion,\n       t.vacuum_sort_benefit,\n       v.vacuum_run_type,\n       v.is_last_vacuum_recluster,\n       v.last_vacuumed_date,\n       v.days_since_last_vacuumed,\n       NVL(s.num_qs,0) query_count,\n       nvl(sat.table_recommendation_count,0) AS table_recommendation_count,\n       c.encoded_column_count,\n       c.column_count,\n       c.encoded_column_pct::NUMERIC(38,4) AS encoded_column_pct,\n       c.encoded_sortkey_count,\n       c.distkey_column_count,\n       nvl(tc.large_column_size_count,0) AS large_column_size_count,\n       tak.alert_sample_query AS sort_key_alert_sample_query,\n       nvl(tak.alert_query_count,0) AS sort_key_alert_query_count,\n       tas.alert_sample_query AS stats_alert_sample_query,\n       nvl(tas.alert_query_count,0) AS stats_alert_query_count,\n       tanl.alert_sample_query AS nl_alert_sample_query,\n       nvl(tanl.alert_query_count,0) AS nl_alert_query_count,\n       tad.alert_sample_query AS distributed_alert_sample_query,\n       nvl(tad.alert_query_count,0) AS distributed_alert_query_count,\n       tab.alert_sample_query AS distributed_alert_sample_query,\n       nvl(tab.alert_query_count,0) AS broadcasted_alert_query_count,\n       tax.alert_sample_query AS deleted_alert_sample_query,\n       nvl(tax.alert_query_count,0) AS deleted_alert_query_count\nFROM SVV_TABLE_INFO t\n  INNER JOIN (SELECT attrelid,\n                     COUNT(1) column_count,\n                     SUM(CASE WHEN attisdistkey = FALSE THEN 0 ELSE 1 END) AS distkey_column_count,\n                     SUM(CASE WHEN attencodingtype IN (0,128) THEN 0 ELSE 1 END) AS encoded_column_count,\n                     1.0 *SUM(CASE WHEN attencodingtype IN (0,128) THEN 0 ELSE 1 END) / COUNT(1)*100 encoded_column_pct,\n                     SUM(CASE WHEN attencodingtype NOT IN (0,128) AND attsortkeyord \u003E 0 THEN 1 ELSE 0 END) AS encoded_sortkey_count\n              FROM pg_attribute\n              WHERE attnum \u003E 0\n              GROUP BY attrelid) c ON (c.attrelid = t.table_id)\n  LEFT OUTER JOIN (SELECT tbl,\n                          perm_table_name,\n                          COUNT(DISTINCT query) num_qs\n                   FROM stl_scan s\n                   WHERE s.userid \u003E 1\n                   AND   s.perm_table_name NOT IN ('Internal Worktable','S3')\n                   GROUP BY 1,\n                            2) s ON (s.tbl = t.table_id)\n  LEFT OUTER JOIN (SELECT DATABASE,\n                          table_id,\n                          COUNT(1) AS table_recommendation_count\n                   FROM svv_alter_table_recommendations\n                   GROUP BY DATABASE,\n                            table_id) sat\n               ON (sat.table_id = t.table_id\n              AND sat.database = t.database)\n  LEFT OUTER JOIN (SELECT sc.table_catalog AS database_name,\n                          sc.table_schema,\n                          sc.table_name,\n                          SUM(CASE WHEN sc.character_maximum_length \u003E 1000 THEN 1 ELSE 0 END) AS large_column_size_count\n                   FROM svv_columns sc\n                     INNER JOIN svv_table_info st\n                             ON (sc.table_catalog = st.database\n                            AND sc.table_schema = st.schema\n                            AND sc.table_name = st.table)\n                   WHERE sc.data_type IN ('character varying','character')\n                   AND   sc.character_maximum_length \u003E 1000\n                   AND   sc.table_schema NOT IN ('pg_internal','pg_catalog','pg_automv')\n                   GROUP BY sc.table_catalog,\n                            sc.table_schema,\n                            sc.table_name) tc\n               ON (t.database = tc.database_name\n              AND tc.table_name = t.table\n              AND tc.table_schema = t.schema)\n  LEFT OUTER JOIN (SELECT t.database AS database_name,\n                          t.schema AS schema_name,\n                          t.table AS table_name,\n                          v.table_id,\n                          CASE\n                            WHEN v.status LIKE '%VacuumBG%' THEN 'Automatic'\n                            ELSE 'Manual'\n                          END AS vacuum_run_type,\n                          CASE\n                            WHEN v.is_recluster = 0 THEN 'N'\n                            WHEN v.is_recluster = 1 THEN 'Y'\n                            ELSE NULL\n                          END AS is_last_vacuum_recluster,\n                          CAST(MAX(v.eventtime) AS DATE) AS last_vacuumed_date,\n                          datediff(d,CAST(MAX(v.eventtime) AS DATE),CAST(CURRENT_TIMESTAMP AT TIME ZONE 'UTC' AS DATE)) AS days_since_last_vacuumed\n                   FROM stl_vacuum v\n                     INNER JOIN svv_table_info t ON (t.table_id = v.table_id)\n                   WHERE v.status NOT LIKE '%Started%'\n                   GROUP BY 1,\n                            2,\n                            3,\n                            4,\n                            5,\n                            6) v\n               ON (v.database_name = t.database\n              AND v.table_name = t.table\n              AND v.schema_name = t.schema)\n  LEFT OUTER JOIN (SELECT q.database AS database_name,\n                          TRIM(s.perm_table_name) AS table_name,\n                          MAX(l.query) AS alert_sample_query,\n                          COUNT(DISTINCT l.query) AS alert_query_count\n                   FROM stl_alert_event_log AS l\n                     LEFT JOIN stl_scan AS s\n                            ON s.query = l.query\n                           AND s.slice = l.slice\n                           AND s.segment = l.segment\n                           AND s.userid \u003E 1\n                           AND s.perm_table_name NOT IN ('Internal Worktable', 'S3') \n                     LEFT JOIN stl_query AS q\n                            ON q.query = l.query\n                           AND q.xid = l.xid\n                           AND q.userid \u003E 1\n                   WHERE l.userid \u003E 1\n                   AND   TRIM(s.perm_table_name) IS NOT NULL\n                   AND   l.event_time \u003E= dateadd(DAY,- 7,CURRENT_DATE)\n                   AND   TRIM(split_part(l.event,':',1)) = 'Very selective query filter'\n                   GROUP BY 1,\n                            2) tak\n               ON (tak.database_name = t.database\n              AND tak.table_name = t.table)\n  LEFT OUTER JOIN (SELECT q.database AS database_name,\n                          TRIM(s.perm_table_name) AS table_name,\n                          MAX(l.query) AS alert_sample_query,\n                          COUNT(DISTINCT l.query) AS alert_query_count\n                   FROM stl_alert_event_log AS l\n                     LEFT JOIN stl_scan AS s\n                            ON s.query = l.query\n                           AND s.slice = l.slice\n                           AND s.segment = l.segment\n                           AND s.userid \u003E 1\n                           AND s.perm_table_name NOT IN ('Internal Worktable', 'S3') \n                     LEFT JOIN stl_query AS q\n                            ON q.query = l.query\n                           AND q.xid = l.xid\n                           AND q.userid \u003E 1\n                   WHERE l.userid \u003E 1\n                   AND   TRIM(s.perm_table_name) IS NOT NULL\n                   AND   l.event_time \u003E= dateadd(DAY,- 7,CURRENT_DATE)\n                   AND   TRIM(split_part(l.event,':',1)) = 'Missing query planner statistics'\n                   GROUP BY 1,\n                            2) tas\n               ON (tas.database_name = t.database\n              AND tas.table_name = t.table)\n  LEFT OUTER JOIN (SELECT q.database AS database_name,\n                          TRIM(s.perm_table_name) AS table_name,\n                          MAX(l.query) AS alert_sample_query,\n                          COUNT(DISTINCT l.query) AS alert_query_count\n                   FROM stl_alert_event_log AS l\n                     LEFT JOIN stl_scan AS s\n                            ON s.query = l.query\n                           AND s.slice = l.slice\n                           AND s.segment = l.segment\n                           AND s.userid \u003E 1\n                           AND s.perm_table_name NOT IN ('Internal Worktable', 'S3') \n                     LEFT JOIN stl_query AS q\n                            ON q.query = l.query\n                           AND q.xid = l.xid\n                           AND q.userid \u003E 1\n                   WHERE l.userid \u003E 1\n                   AND   TRIM(s.perm_table_name) IS NOT NULL\n                   AND   l.event_time \u003E= dateadd(DAY,- 7,CURRENT_DATE)\n                   AND   TRIM(split_part(l.event,':',1)) = 'Nested Loop Join in the query plan'\n                   GROUP BY 1,\n                            2) tanl\n               ON (tanl.database_name = t.database\n              AND tanl.table_name = t.table)\n  LEFT OUTER JOIN (SELECT q.database AS database_name,\n                          TRIM(s.perm_table_name) AS table_name,\n                          MAX(l.query) AS alert_sample_query,\n                          COUNT(DISTINCT l.query) AS alert_query_count\n                   FROM stl_alert_event_log AS l\n                     LEFT JOIN stl_scan AS s\n                            ON s.query = l.query\n                           AND s.slice = l.slice\n                           AND s.segment = l.segment\n                           AND s.userid \u003E 1\n                           AND s.perm_table_name NOT IN ('Internal Worktable', 'S3') \n                     LEFT JOIN stl_query AS q\n                            ON q.query = l.query\n                           AND q.xid = l.xid\n                           AND q.userid \u003E 1\n                   WHERE l.userid \u003E 1\n                   AND   TRIM(s.perm_table_name) IS NOT NULL\n                   AND   l.event_time \u003E= dateadd(DAY,- 7,CURRENT_DATE)\n                   AND   TRIM(split_part(l.event,':',1)) = 'Distributed a large number of rows across the network'\n                   GROUP BY 1,\n                            2) tad\n               ON (tad.database_name = t.database\n              AND tad.table_name = t.table)\n  LEFT OUTER JOIN (SELECT q.database AS database_name,\n                          TRIM(s.perm_table_name) AS table_name,\n                          MAX(l.query) AS alert_sample_query,\n                          COUNT(DISTINCT l.query) AS alert_query_count\n                   FROM stl_alert_event_log AS l\n                     LEFT JOIN stl_scan AS s\n                            ON s.query = l.query\n                           AND s.slice = l.slice\n                           AND s.segment = l.segment\n                           AND s.userid \u003E 1\n                           AND s.perm_table_name NOT IN ('Internal Worktable', 'S3') \n                     LEFT JOIN stl_query AS q\n                            ON q.query = l.query\n                           AND q.xid = l.xid\n                           AND q.userid \u003E 1\n                   WHERE l.userid \u003E 1\n                   AND   TRIM(s.perm_table_name) IS NOT NULL\n                   AND   l.event_time \u003E= dateadd(DAY,- 7,CURRENT_DATE)\n                   AND   TRIM(split_part(l.event,':',1)) = 'Broadcasted a large number of rows across the network'\n                   GROUP BY 1,\n                            2) tab\n               ON (tab.database_name = t.database\n              AND tab.table_name = t.table)\n  LEFT OUTER JOIN (SELECT q.database AS database_name,\n                          TRIM(s.perm_table_name) AS table_name,\n                          MAX(l.query) AS alert_sample_query,\n                          COUNT(DISTINCT l.query) AS alert_query_count\n                   FROM stl_alert_event_log AS l\n                     LEFT JOIN stl_scan AS s\n                            ON s.query = l.query\n                           AND s.slice = l.slice\n                           AND s.segment = l.segment\n                           AND s.userid \u003E 1\n                           AND s.perm_table_name NOT IN ('Internal Worktable', 'S3') \n                     LEFT JOIN stl_query AS q\n                            ON q.query = l.query\n                           AND q.xid = l.xid\n                           AND q.userid \u003E 1\n                   WHERE l.userid \u003E 1\n                   AND   TRIM(s.perm_table_name) IS NOT NULL\n                   AND   l.event_time \u003E= dateadd(DAY,- 7,CURRENT_DATE)\n                   AND   TRIM(split_part(l.event,':',1)) = 'Scanned a large number of deleted rows'\n                   GROUP BY 1,\n                            2) tax\n               ON (tax.database_name = t.database\n              AND tax.table_name = t.table)\nWHERE t.\"schema\" NOT IN ('pg_internal','pg_catalog','pg_automv')\nAND   t.\"schema\" NOT LIKE 'pg_temp%'\nORDER BY tbl_rows DESC;"
    },
    "AlterTableRecommendations": {
        "SQL": "SELECT r.type,\n       trim(t.database_name) AS dbname,\n       t.schema_name AS namespace,\n       r.table_id,\n       t.table_name,\n       r.group_id,\n       r.ddl,\n       r.auto_eligible\nFROM svv_alter_table_recommendations r\n  INNER JOIN (SELECT DISTINCT(stv_tbl_perm.id) AS table_id\n                    ,TRIM(pg_database.datname) AS database_name\n                    ,TRIM(pg_namespace.nspname) AS schema_name\n                    ,TRIM(relname) AS table_name\n                FROM stv_tbl_perm\n              INNER JOIN pg_database on pg_database.oid = stv_tbl_perm.db_id\n              INNER JOIN pg_class on pg_class.oid = stv_tbl_perm.id\n              INNER JOIN pg_namespace on pg_namespace.oid = pg_class.relnamespace\n               WHERE schema_name NOT IN ('pg_internal', 'pg_catalog','pg_automv')) t\n          ON (r.database = t.database_name\n         AND r.table_id = t.table_id);"
    },
    "MaterializedView": {
        "SQL": "WITH mv_info AS\n(\n  SELECT trim(db_name) AS dbname,\n         trim(\"schema\") AS namespace, \n         trim(name) AS mview_name,\n         is_stale,\n         state,\n         CASE state\n           WHEN 0 THEN 'The MV is fully recomputed when refreshed'\n           WHEN 1 THEN 'The MV is incremental'\n           WHEN 101 THEN 'The MV cant be refreshed due to a dropped column. This constraint applies even if the column isnt used in the MV'\n           WHEN 102 THEN 'The MV cant be refreshed due to a changed column type. This constraint applies even if the column isnt used in the MV'\n           WHEN 103 THEN 'The MV cant be refreshed due to a renamed table'\n           WHEN 104 THEN 'The MV cant be refreshed due to a renamed column. This constraint applies even if the column isnt used in the MV'\n           WHEN 105 THEN 'The MV cant be refreshed due to a renamed schema'\n           ELSE NULL\n         END AS state_desc,\n         autorewrite,\n         autorefresh\n  FROM stv_mv_info\n),\nmv_state AS\n(\n  SELECT dbname,\n         namespace,\n         mview_name,\n         state AS mv_state,\n         event_desc,\n         starttime AS event_starttime\n  FROM (SELECT trim(db_name) AS dbname,\n               trim(mv_schema) AS namespace, \n               trim(mv_name) AS mview_name,\n               ROW_NUMBER() OVER (PARTITION BY db_name, mv_schema, mv_name ORDER BY starttime DESC) AS rnum,\n               state,\n               event_desc,\n               starttime\n        FROM stl_mv_state)\n  WHERE rnum = 1\n),\nmv_ref_status AS\n(\n  SELECT dbname,\n         refresh_db_username,\n         namespace,\n         mview_name,\n         status AS refresh_status,\n         refresh_type,\n         starttime AS refresh_starttime,\n         endtime AS refresh_endtime,\n         datediff(ms, starttime, endtime)*1.0/1000 AS refresh_duration_secs\n  FROM (SELECT trim(r.db_name) AS dbname,\n               trim(r.schema_name) AS namespace, \n               pu.usename as refresh_db_username,\n               trim(r.mv_name) AS mview_name,\n               ROW_NUMBER() OVER (PARTITION BY r.db_name, r.schema_name, r.userid, r.mv_name ORDER BY starttime DESC) AS rnum,\n               r.status,\n               r.refresh_type,\n               r.starttime,\n               r.endtime\n        FROM svl_mv_refresh_status r\n        INNER JOIN pg_user pu on (r.userid = pu.usesysid))\n  WHERE rnum = 1\n)\nSELECT i.*, \n       s.mv_state, s.event_desc, s.event_starttime,\n       r.refresh_db_username, r.refresh_status, r.refresh_type, r.refresh_starttime, r.refresh_endtime, r.refresh_duration_secs\nFROM mv_info i\n  LEFT JOIN mv_state s ON (i.dbname = s.dbname AND i.namespace = s.namespace AND i.mview_name = s.mview_name)\n  LEFT JOIN mv_ref_status r ON (i.dbname = r.dbname AND i.namespace = r.namespace AND i.mview_name = r.mview_name);"
    },
    "Top50QueriesByRunTime": {
        "SQL": "SELECT TRIM(dbname) AS dbname,\n       TRIM(db_username) AS db_username,\n       MAX(SUBSTRING(replace(qrytext,chr (34),chr (92) + chr (34)),1,500)) AS qrytext,\n       COUNT(query) AS num_queries,\n       MIN(run_minutes) AS min_minutes,\n       MAX(run_minutes) AS max_minutes,\n       AVG(run_minutes) AS avg_minutes,\n       SUM(run_minutes) AS total_minutes,\n       SUM(compile_minutes) AS total_compile_minutes,\n       SUM(num_compile_segments) AS total_num_compile_segments,\n       MIN(query_temp_blocks_to_disk_mb) AS min_disk_spill_mb,\n       MAX(query_temp_blocks_to_disk_mb) AS max_disk_spill_mb,\n       AVG(query_temp_blocks_to_disk_mb) AS avg_disk_spill_mb,\n       SUM(query_temp_blocks_to_disk_mb) AS total_disk_spill_mb,\n       MAX(query) AS max_query_id,\n       MAX(starttime)::DATE AS last_run,\n       COUNT(DISTINCT starttime::DATE) AS num_days_executed,\n       SUM(aborted) AS total_aborted,\n       MAX(mylabel) qry_label,\n       AVG(spectrum_object_count) AS avg_spectrum_object_used,\n       AVG(federated_object_count) AS avg_federated_object_used,\n       user_table_involved,\n       TRIM(DECODE (event & 1,1,'Sortkey ','') || DECODE (event & 2,2,'Deletes ','') || DECODE (event & 4,4,'NL ','') || DECODE (event & 8,8,'Dist ','') || DECODE (event & 16,16,'Broacast ','') || DECODE (event & 32,32,'Stats ','')) AS Alert\nFROM (SELECT stl_query.userid,\n             pu.usename as db_username,\n             label,\n             stl_query.query,\n             TRIM(\"DATABASE\") AS dbname,\n             NVL(qrytext_cur.text,TRIM(querytxt)) AS qrytext,\n             MD5(NVL (qrytext_cur.text,TRIM(querytxt))) AS qry_md5,\n             starttime,\n             endtime,\n             DATEDIFF(seconds,starttime,endtime)::NUMERIC(12,2) / 60 AS run_minutes,\n             aborted,\n             event,\n             stl_query.label AS mylabel,\n             CASE\n               WHEN sqms.query_temp_blocks_to_disk IS NULL THEN 0\n               ELSE sqms.query_temp_blocks_to_disk\n             END AS query_temp_blocks_to_disk_mb,\n             nvl(compile_secs,0)::NUMERIC(12,2) / 60 AS compile_minutes,\n             nvl(num_compile_segments,0) AS num_compile_segments,\n             s.user_table_involved,\n             NVL(s3.spectrum_object_count,0) AS spectrum_object_count,\n             NVL(f.federated_object_count,0) AS federated_object_count\n      FROM stl_query\n\t  INNER JOIN pg_catalog.pg_user pu on (stl_query.userid = pu.usesysid)\n        LEFT OUTER JOIN (SELECT query,\n                                SUM(DECODE (TRIM(SPLIT_PART (event,':',1)),'Very selective query filter',1,'Scanned a large number of deleted rows',2,'Nested Loop Join in the query plan',4,'Distributed a large number of rows across the network',8,'Broadcasted a large number of rows across the network',16,'Missing query planner statistics',32,0)) AS event\n                         FROM stl_alert_event_log\n                         WHERE event_time \u003E= DATEADD(DAY,-7,CURRENT_DATE)\n                         GROUP BY query) AS alrt ON alrt.query = stl_query.query\n        LEFT OUTER JOIN (SELECT ut.xid,\n                                TRIM(SUBSTRING(text FROM STRPOS (UPPER(text),'SELECT'))) AS TEXT\n                         FROM stl_utilitytext ut\n                         WHERE SEQUENCE = 0\n                         AND   text ilike 'DECLARE%'\n                         GROUP BY text,\n                                  ut.xid) qrytext_cur ON (stl_query.xid = qrytext_cur.xid)\n        LEFT OUTER JOIN svl_query_metrics_summary sqms\n                     ON (sqms.userid = stl_query.userid\n                    AND sqms.query = stl_query.query)\n        LEFT OUTER JOIN (SELECT userid,\n                                xid,\n                                pid,\n                                query,\n                                MAX(datediff (ms,starttime,endtime)*1.0 / 1000) AS compile_secs,\n                                SUM(compile) AS num_compile_segments\n                         FROM svcs_compile\n                         GROUP BY userid,\n                                  xid,\n                                  pid,\n                                  query) c\n                     ON (c.userid = stl_query.userid\n                    AND c.xid = stl_query.xid\n                    AND c.pid = stl_query.pid\n                    AND c.query = stl_query.query)\n        LEFT OUTER JOIN (SELECT s.userid,\n                                s.query,\n                                LISTAGG(DISTINCT TRIM(s.perm_table_name),', ') AS user_table_involved\n                         FROM stl_scan s\n                             INNER JOIN (SELECT DISTINCT(stv_tbl_perm.id) AS table_id\n                    ,TRIM(pg_database.datname) AS database_name\n                    ,TRIM(pg_namespace.nspname) AS schema_name\n                    ,TRIM(relname) AS table_name\n                FROM stv_tbl_perm\n              INNER JOIN pg_database on pg_database.oid = stv_tbl_perm.db_id\n              INNER JOIN pg_class on pg_class.oid = stv_tbl_perm.id\n              INNER JOIN pg_namespace on pg_namespace.oid = pg_class.relnamespace\n               WHERE schema_name NOT IN ('pg_internal', 'pg_catalog','pg_automv')) t ON (s.tbl = t.table_id)\n                         WHERE s.perm_table_name NOT IN ('Internal Worktable','S3')\n                         AND   s.perm_table_name NOT LIKE ('volt_tt%')\n                         AND   t.schema_name NOT IN ('pg_internal','pg_catalog')\n                         GROUP BY s.userid,\n                                  s.query) s\n                     ON (stl_query.userid = s.userid\n                    AND stl_query.query = s.query)\n        LEFT OUTER JOIN (SELECT s.userid,\n                                s.query,\n                                COUNT(1) AS spectrum_object_count\n                         FROM svl_s3query_summary s\n                         WHERE s.external_table_name NOT IN ('PG Subquery')\n                         GROUP BY s.userid,\n                                  s.query) s3\n                     ON (stl_query.userid = s3.userid\n                    AND stl_query.query = s3.query)\n        LEFT OUTER JOIN (SELECT f.userid,\n                                f.query,\n                                COUNT(1) AS federated_object_count\n                         FROM svl_federated_query f\n                         GROUP BY f.userid,\n                                  f.query) f\n                     ON (stl_query.userid = f.userid\n                    AND stl_query.query = f.query)\n      WHERE stl_query.userid \u003C\u003E 1\n      AND   NVL(qrytext_cur.text,TRIM(querytxt)) NOT LIKE 'padb_fetch_sample:%'\n      AND   NVL(qrytext_cur.text,TRIM(querytxt)) NOT LIKE 'CREATE TEMP TABLE volt_tt_%'\n      AND   stl_query.starttime \u003E= DATEADD(DAY,-7,CURRENT_DATE))\nGROUP BY TRIM(dbname),\n         TRIM(db_username),\n         qry_md5,\n         user_table_involved,\n         event\nORDER BY avg_minutes DESC, num_queries DESC LIMIT 50;"
    },
    "Top50QueriesByDiskSpill": {
        "SQL": "SELECT TRIM(dbname) AS dbname,\n       TRIM(db_username) AS db_username,\n       MAX(SUBSTRING(replace(qrytext,chr (34),chr (92) + chr (34)),1,500)) AS qrytext,\n       COUNT(query) AS num_queries,\t    \n       MIN(run_minutes) AS min_minutes,\n       MAX(run_minutes) AS max_minutes,\n       AVG(run_minutes) AS avg_minutes,\n       SUM(run_minutes) AS total_minutes,\n       SUM(compile_minutes) AS total_compile_minutes,\n       SUM(num_compile_segments) AS total_num_compile_segments,\n       MIN(query_temp_blocks_to_disk_mb) AS min_disk_spill_mb,\n       MAX(query_temp_blocks_to_disk_mb) AS max_disk_spill_mb,\n       AVG(query_temp_blocks_to_disk_mb) AS avg_disk_spill_mb,\n       SUM(query_temp_blocks_to_disk_mb) AS total_disk_spill_mb,\n       MAX(query) AS max_query_id,\n       MAX(starttime)::DATE AS last_run,\n       COUNT(DISTINCT starttime::DATE) AS num_days_executed,\t\t   \n       SUM(aborted) as total_aborted,\n       MAX(mylabel) qry_label,\n\t   AVG(spectrum_object_count) AS avg_spectrum_object_used,\n\t   AVG(federated_object_count) AS avg_federated_object_used,\n\t   user_table_involved,\n       TRIM(DECODE (event & 1,1,'Sortkey ','') || DECODE (event & 2,2,'Deletes ','') || DECODE (event & 4,4,'NL ','') || DECODE (event & 8,8,'Dist ','') || DECODE (event & 16,16,'Broacast ','') || DECODE (event & 32,32,'Stats ','')) AS Alert\nFROM (SELECT stl_query.userid,\n             pu.usename as db_username,\n             label,\n             stl_query.query,\n             TRIM(\"DATABASE\") AS dbname,\n             NVL(qrytext_cur.text,TRIM(querytxt)) AS qrytext,\n             MD5(NVL (qrytext_cur.text,TRIM(querytxt))) AS qry_md5,\n             starttime,\n             endtime,\n             DATEDIFF(seconds,starttime,endtime)::NUMERIC(12,2) / 60 AS run_minutes,\n             aborted,\n             event,\n             stl_query.label AS mylabel,\n             CASE\n               WHEN sqms.query_temp_blocks_to_disk IS NULL THEN 0\n               ELSE sqms.query_temp_blocks_to_disk\n             END AS query_temp_blocks_to_disk_mb,\n             nvl(compile_secs,0)::NUMERIC(12,2) / 60 AS compile_minutes,\n             nvl(num_compile_segments,0) AS num_compile_segments,\n\t\t\t s.user_table_involved,\n\t\t\t NVL(s3.spectrum_object_count,0) AS spectrum_object_count,\n\t\t\t NVL(f.federated_object_count,0) AS federated_object_count\n        FROM stl_query\n\t\tINNER JOIN pg_catalog.pg_user pu on (stl_query.userid = pu.usesysid)\n        LEFT OUTER JOIN (SELECT query,\n                                SUM(DECODE (TRIM(SPLIT_PART (event,':',1)),'Very selective query filter',1,'Scanned a large number of deleted rows',2,'Nested Loop Join in the query plan',4,'Distributed a large number of rows across the network',8,'Broadcasted a large number of rows across the network',16,'Missing query planner statistics',32,0)) AS event\n                         FROM stl_alert_event_log\n                         WHERE event_time \u003E= DATEADD(DAY,-7,CURRENT_DATE)\n                         GROUP BY query) AS alrt ON alrt.query = stl_query.query\n        LEFT OUTER JOIN (SELECT ut.xid,\n                                TRIM(SUBSTRING(text FROM STRPOS (UPPER(text),'SELECT'))) AS TEXT\n                         FROM stl_utilitytext ut\n                         WHERE SEQUENCE = 0\n                         AND   text ilike 'DECLARE%'\n                         GROUP BY text,\n                                  ut.xid) qrytext_cur ON (stl_query.xid = qrytext_cur.xid)\n        LEFT OUTER JOIN svl_query_metrics_summary sqms\n                     ON (sqms.userid = stl_query.userid AND sqms.query = stl_query.query)\n        LEFT OUTER JOIN (SELECT userid,\n                                xid,\n                                pid,\n                                query,\n                                MAX(datediff (ms,starttime,endtime)*1.0 / 1000) AS compile_secs,\n                                SUM(compile) AS num_compile_segments\n                         FROM svcs_compile\n                         GROUP BY userid,\n                                  xid,\n                                  pid,\n                                  query) c\n                     ON (c.userid = stl_query.userid\n                    AND c.xid = stl_query.xid\n                    AND c.pid = stl_query.pid\n                    AND c.query = stl_query.query)\n        LEFT OUTER JOIN (SELECT s.userid,\n                                s.query,\n                                LISTAGG(distinct TRIM(s.perm_table_name),', ') AS user_table_involved\n                           FROM stl_scan s\n                             INNER JOIN (SELECT DISTINCT(stv_tbl_perm.id) AS table_id\n                    ,TRIM(pg_database.datname) AS database_name\n                    ,TRIM(pg_namespace.nspname) AS schema_name\n                    ,TRIM(relname) AS table_name\n                FROM stv_tbl_perm\n              INNER JOIN pg_database on pg_database.oid = stv_tbl_perm.db_id\n              INNER JOIN pg_class on pg_class.oid = stv_tbl_perm.id\n              INNER JOIN pg_namespace on pg_namespace.oid = pg_class.relnamespace\n               WHERE schema_name NOT IN ('pg_internal', 'pg_catalog','pg_automv')) t ON (s.tbl = t.table_id)\n                          WHERE s.perm_table_name NOT IN ('Internal Worktable','S3')\n\t\t\t\t\t\t    AND s.perm_table_name NOT LIKE ('volt_tt%')\n                            AND t.schema_name NOT IN ('pg_internal', 'pg_catalog') \n                         GROUP BY s.userid,\n                                  s.query) s ON (stl_query.userid = s.userid AND stl_query.query = s.query)\t\n        LEFT OUTER JOIN (SELECT s.userid,\n                                s.query,\n                                COUNT(1) AS spectrum_object_count \n                           FROM svl_s3query_summary s \n\t\t\t\t\t\t  WHERE s.external_table_name NOT IN ('PG Subquery')\n                         GROUP BY s.userid,\n                                  s.query) s3 ON (stl_query.userid = s3.userid AND stl_query.query = s3.query)\n        LEFT OUTER JOIN (SELECT f.userid,\n                                f.query,\n                                COUNT(1) AS federated_object_count \n                           FROM svl_federated_query f \n                         GROUP BY f.userid,\n                                  f.query) f ON (stl_query.userid = f.userid AND stl_query.query = f.query)\t\t\t\t\t\t\t\t  \n      WHERE stl_query.userid \u003C\u003E 1\n\t    AND NVL(qrytext_cur.text,TRIM(querytxt)) NOT LIKE 'padb_fetch_sample:%' \n\t\tAND NVL(qrytext_cur.text,TRIM(querytxt)) NOT LIKE 'CREATE TEMP TABLE volt_tt_%'\n        AND stl_query.starttime \u003E= DATEADD(DAY,-7,CURRENT_DATE))\nGROUP BY TRIM(dbname),\n         TRIM(db_username),\n         qry_md5,\n\t\t user_table_involved,\n         event\nORDER BY avg_disk_spill_mb DESC, num_queries DESC LIMIT 50;"
    },
    "CopyPerformance": {
        "SQL": "SELECT a.endtime::DATE AS copy_date,\n       trim(d.region) AS aws_region,\n       trim(d.s3_bucket) AS s3_bucket,\n       trim(d.file_format) AS file_format,\n       trim(q.\"database\") as dbname,\n       a.tbl AS table_id,\n       trim(c.nspname) AS namespace,\n       trim(b.relname) AS table_name,\n       SUM(a.rows_inserted) AS rows_inserted,\n       SUM(d.distinct_files) AS files_scanned,\n       SUM(d.mb_scanned) AS mb_scanned,\n       (SUM(d.distinct_files)::NUMERIC(19,3) / COUNT(DISTINCT a.query)::NUMERIC(19,3))::NUMERIC(19,3) AS avg_files_per_copy,\n       (SUM(d.mb_scanned) / SUM(d.distinct_files)::NUMERIC(19,3))::NUMERIC(19,3) AS avg_file_size_mb,\n       MAX(d.files_compressed) AS files_compressed,\n       MAX(cluster_slice_count) AS cluster_slice_count,\n       AVG(d.used_slice_count) AS avg_used_slice_count,\n       COUNT(DISTINCT a.query) no_of_copy,\n       MAX(a.query) AS sample_query,\n       ROUND((SUM(d.mb_scanned)*1024 *1000000.0 / SUM(d.load_micro)),4) AS scan_rate_kbps,\n       ROUND((SUM(a.rows_inserted)*1000000.0 / SUM(a.insert_micro)),4) AS insert_rate_rows_per_second,\n       ROUND(SUM(d.copy_duration_micro)/1000000.0,4) AS total_copy_time_secs,\n       ROUND(AVG(d.copy_duration_micro)/1000000.0,4) AS avg_copy_time_secs,\n       ROUND(SUM(d.compression_micro)/1000000.0,4) AS total_compression_time_secs,\n       ROUND(AVG(d.compression_micro)/1000000.0,4) AS avg_compression_time_secs,       \n       SUM(d.total_transfer_retries) AS total_transfer_retries,\n       SUM(d.distinct_error_files) AS distinct_error_files,\n       SUM(d.load_error_count) AS load_error_count\nFROM (SELECT query,\n             tbl,\n             SUM(ROWS) AS rows_inserted,\n             MAX(endtime) AS endtime,\n             datediff('microsecond',MIN(starttime),MAX(endtime)) AS insert_micro\n      FROM stl_insert\n      GROUP BY query,\n               tbl) a,\n     pg_class b,\n     pg_namespace c,\n     (SELECT b.region,\n             l.file_format,\n             b.query,\n             b.bucket as s3_bucket,\n             COUNT(DISTINCT b.bucket||b.key) AS distinct_files,\n             COUNT(DISTINCT b.slice) as used_slice_count,\n             SUM(b.transfer_size) / 1024 / 1024 AS mb_scanned,\n             SUM(b.transfer_time) AS load_micro,\n             SUM(b.compression_time) AS compression_micro,\n             datediff('microsecond',MIN('2000-01-01'::timestamp + (start_time/1000000.0)* interval '1 second'),MAX('2000-01-01'::timestamp + (end_time/1000000.0)* interval '1 second')) AS copy_duration_micro,\n             SUM(b.retries) as total_transfer_retries,\n             SUM(nvl(se.distinct_error_files,0)) AS distinct_error_files,\n             SUM(nvl(se.load_error_count,0)) AS load_error_count,\n             CASE WHEN SUM(b.transfer_size) = SUM(b.data_size) then 'N' else  'Y' end AS files_compressed\n      FROM stl_s3client b\n      INNER JOIN (select userid, query, MAX(file_format) as file_format FROM stl_load_commits GROUP BY userid, query) l ON (l.userid = b.userid and l.query = b.query)\n      LEFT OUTER JOIN (select userid, query, COUNT(DISTINCT bucket||key) AS distinct_error_files, COUNT(1) AS load_error_count FROM stl_s3client_error GROUP BY userid, query) se ON (se.userid = b.userid and se.query = b.query)\n      WHERE b.http_method = 'GET'\n      GROUP BY b.region,l.file_format,b.query,b.bucket) d,\n     stl_query q,\n     (SELECT COUNT(1) AS cluster_slice_count FROM stv_slices)\nWHERE a.tbl = b.oid\nAND   b.relnamespace = c.oid\nAND   d.query = a.query\nAND   a.query = q.query\nAND   lower(q.querytxt) LIKE '%copy %'\nGROUP BY 1,2,3,4,5,6,7,8\nORDER BY 9 DESC, 21 DESC, 1 DESC\n LIMIT 50;"
    },
    "SpectrumPerformance": {
        "SQL": "SELECT trim(et.schemaname) AS namespace,\n       trim(et.tablename) AS external_table_name,\n       trim(lq.file_format) AS file_format,\n       trim(l.s3_bucket) AS s3_bucket,\n       CASE\n         WHEN et.compressed = 1 THEN 'Y'\n         ELSE 'N'\n       END AS is_table_compressed,\n       CASE\n         WHEN lq.is_partitioned = 't' THEN 'Y'\n         ELSE 'N'\n       END AS is_table_partitioned,\n       CASE\n         WHEN l.avg_file_splits \u003E 1 THEN 'Y'\n         ELSE 'N'\n       END AS is_file_spittable,\n       MAX(nvl (ep.external_table_partition_count,0)) AS external_table_partition_count,\n       COUNT(1) total_query_count,\n       SUM(CASE WHEN lp.qualified_partitions \u003C ep.external_table_partition_count THEN 1 ELSE 0 END) total_query_using_Partition_Pruning_count,\n       ROUND(SUM(CASE WHEN lp.qualified_partitions \u003C ep.external_table_partition_count THEN 1 ELSE 0 END) / COUNT(1)::NUMERIC(38,4)*100.0,4) AS pct_of_query_using_Partition_Pruning,\n       nvl(AVG(CASE WHEN lp.qualified_partitions != 0 THEN lp.qualified_partitions END),0) AS avg_Qualified_Partitions,\n       nvl(AVG(CASE WHEN lp.qualified_partitions != 0 THEN lp.avg_assigned_partitions END),0) AS avg_Assigned_Partitions,\n       ROUND(nvl(AVG(CASE WHEN lp.qualified_partitions != 0 THEN lq.avg_request_parallelism END),0),4) AS avg_Parallelism,\n       nvl(AVG(CASE WHEN lp.qualified_partitions != 0 THEN lq.files END),0) AS avg_Files,\n       AVG(lq.splits) AS avg_Split,\n       ROUND(AVG(l.avg_max_file_size_mb),4) AS avg_max_file_size_mb,\n       ROUND(AVG(l.avg_file_size_mb),4) AS avg_file_size_mb,\n       ROUND(AVG(elapsed / 1000000::NUMERIC(38,4)),4) avg_Elapsed_sec,\n       ROUND(SUM(elapsed / 1000000::NUMERIC(38,4)),4) Total_Elapsed_sec,\n       SUM(nvl(r.spectrum_scan_error_count,0)) AS total_spectrum_scan_error_count,\n       AVG(nvl(r.spectrum_scan_error_count,0)) AS avg_spectrum_scan_error_count,\n       SUM(CASE WHEN lp.qualified_partitions = 0 THEN 1 ELSE 0 END) Queries_Using_No_S3Files\nFROM svl_s3query_summary lq\n  INNER JOIN stl_query q\n          ON (q.userid = lq.userid\n         AND q.query = lq.query\n         AND q.xid = lq.xid\n         AND q.pid = lq.pid)\n  INNER JOIN svv_external_tables et ON (q.database || '_' || et.schemaname || '_' || et.tablename = replace (replace (lq.external_table_name,'S3 Scan ',''),'S3 Subquery ',''))\n  LEFT OUTER JOIN (SELECT schemaname,\n                          tablename,\n                          COUNT(1) AS external_table_partition_count\n                   FROM svv_external_partitions\n                   GROUP BY schemaname,\n                            tablename) ep\n               ON (ep.schemaname = et.schemaname\n              AND ep.tablename = et.tablename)\n  LEFT OUTER JOIN svl_s3partition_summary lp ON lq.query = lp.query\n  LEFT OUTER JOIN (SELECT query,\n                          bucket AS s3_bucket,\n                          AVG(max_file_size / 1000000.0) AS avg_max_file_size_mb,\n                          AVG(avg_file_size / 1000000.0) AS avg_file_size_mb,\n                          AVG(generated_splits) AS avg_file_splits\n                   FROM svl_s3list\n                   GROUP BY query,\n                            bucket) l ON (lq.query = l.query)\n  LEFT OUTER JOIN (SELECT query,\n                          userid,\n                          count(1) AS spectrum_scan_error_count\n                   FROM svl_spectrum_scan_error\n                   GROUP BY query, userid) r ON (lq.query = r.query and lq.userid = r.userid)\nWHERE lq.starttime \u003E= dateadd(day,- 7,CURRENT_DATE)\nAND   lq.aborted = 0\nGROUP BY 1,2,3,4,5,6,7\nORDER BY Total_Elapsed_sec DESC LIMIT 50;"
    },
    "DataShareProducerObject": {
        "SQL": "WITH shared_table AS\n(\n  SELECT t.schema_name|| '.' ||t.table_name AS object_name,\n         MAX(t.table_rows) AS table_rows,\n         MAX(v.eventtime) AS last_vacuum_date,\n         MAX(CASE WHEN v.is_recluster = 0 THEN 'N' WHEN v.is_recluster = 1 THEN 'Y' ELSE NULL END) AS is_last_vacuum_recluster,\n         MAX(i.num_insert_operation) AS num_insert_operation,\n         MAX(i.total_inserted_rows) AS total_inserted_rows,\n         MAX(i.last_insert_date) AS last_insert_date,\n         MAX(d.num_delete_operation) AS num_delete_operation,\n         MAX(d.total_deleted_rows) AS total_deleted_rows,\n         MAX(d.last_delete_date) AS last_delete_date\n  FROM (SELECT DISTINCT (stv_tbl_perm.id) table_id,\n               TRIM(pg_database.datname) AS \"database\",\n               TRIM(pg_namespace.nspname) AS schema_name,\n               TRIM(relname) AS table_name,\n               reltuples::bigint AS table_rows\n        FROM stv_tbl_perm\n          JOIN pg_database ON pg_database.oid = stv_tbl_perm.db_id\n          JOIN pg_class ON pg_class.oid = stv_tbl_perm.id\n          JOIN pg_namespace ON pg_namespace.oid = pg_class.relnamespace\n        WHERE schema_name NOT IN ('pg_internal','pg_catalog','pg_automv')) t\n    LEFT OUTER JOIN stl_vacuum v\n                 ON (t.table_id = v.table_id\n                AND v.status NOT LIKE 'Skip%')\n    LEFT OUTER JOIN (SELECT tbl,\n                            COUNT(1) AS num_insert_operation,\n                            SUM(ROWS) AS total_inserted_rows,\n                            MAX(endtime) AS last_insert_date\n                     FROM stl_insert\n                     GROUP BY 1) i ON (i.tbl = t.table_id)\n    LEFT OUTER JOIN (SELECT tbl,\n                            COUNT(1) AS num_delete_operation,\n                            SUM(ROWS) AS total_deleted_rows,\n                            MAX(endtime) AS last_delete_date\n                     FROM stl_delete\n                     GROUP BY 1) d ON (d.tbl = t.table_id)\n  GROUP BY 1\n)\nSELECT d.share_type,\n       d.share_name,\n       case when d.include_new = true then 'True' when d.include_new = false then 'False' else null end as include_new,\n       d.producer_account,\n       d.object_type,\n       replace(substring(d.object_name,1,strpos (d.object_name,'.')),'.','') AS namespace,\n       substring(d.object_name,strpos (d.object_name,'.') +1) AS object_name,\n       ti.table_rows,\n       ti.last_vacuum_date,\n       ti.is_last_vacuum_recluster,\n       ti.num_insert_operation,\n       ti.total_inserted_rows,\n       ti.last_insert_date,\n       ti.num_delete_operation,\n       ti.total_deleted_rows,\n       ti.last_delete_date,\n       CASE\n         WHEN mi.is_stale = 't' THEN 'Y'\n         WHEN mi.is_stale = 'f' THEN 'N'\n         ELSE NULL\n       END AS is_mv_stale,\n       CASE\n         WHEN mi.state = 1 THEN 'Y'\n         WHEN mi.state \u003C\u003E 1 THEN 'N'\n         ELSE NULL\n       END AS is_mv_incremental_refresh,\n       CASE\n         WHEN mi.autorefresh = 1 THEN 'Y'\n         WHEN mi.autorefresh \u003C\u003E 1 THEN 'N'\n         ELSE NULL\n       END AS is_mv_auto_refresh\nFROM svv_datashare_objects d\n  LEFT OUTER JOIN shared_table ti ON (d.object_name = ti.object_name)\n  LEFT OUTER JOIN stv_mv_info mi ON (d.object_name = mi.schema|| '.' ||mi.name)\nWHERE d.share_type = 'OUTBOUND'\nORDER BY 2,3,5,4;"
    },
    "DataShareConsumerUsage": {
        "SQL": "with consumer_activity as \n(\nselect uc.userid\n      ,u.usename as db_username\n      ,uc.pid\n      ,uc.xid\n      ,min(uc.recordtime) as request_start_date\n      ,max(uc.recordtime) as request_end_date\n      ,datediff('milliseconds',min(uc.recordtime),max(uc.recordtime))::NUMERIC(38,4) / 1000 as request_duration_secs\n      ,nvl(count(distinct uc.transaction_uid),0) as unique_transaction\n      ,nvl(count(uc.request_id),0) as total_usage_consumer_count\n      ,sum(case when trim(uc.error) = '' then 0 else 1 end) as request_error_count\n  from svl_datashare_usage_consumer uc\n  inner join pg_user u on (u.usesysid = uc.userid)\ngroup by 1,2,3,4\n)\n,consumer_query as (\nselect trim(q.\"database\") as dbname\n      ,trim(cu.db_username) as db_username\n      ,cu.request_start_date::date as request_date\n      ,cu.request_duration_secs\n      ,datediff('milliseconds',cu.request_end_date,q.starttime)::NUMERIC(38,4) / 1000  as request_interval_secs\n      ,datediff('milliseconds',q.starttime,q.endtime)::NUMERIC(38,4) / 1000 as query_execution_secs\n      ,datediff('milliseconds',request_start_date,q.endtime)::NUMERIC(38,4) / 1000 as total_execution_secs\n      ,q.query\n      ,cu.unique_transaction\n      ,cu.total_usage_consumer_count\n      ,cu.request_error_count      \nfrom consumer_activity cu \ninner join stl_query q on (q.xid = cu.xid and q.pid = cu.pid and q.userid = cu.userid)\n)\n,consumer_query_aggregate as (\nselect cq.request_date\n      ,cq.dbname\n      ,cq.db_username\n\t  ,avg(cq.request_duration_secs) as avg_request_duration_secs\n      ,sum(cq.request_duration_secs) as total_request_duration_secs\n\t  ,avg(cq.request_interval_secs) as avg_request_interval_secs\n      ,sum(cq.request_interval_secs) as total_request_interval_secs\n\t  ,avg(cq.query_execution_secs) as avg_query_execution_secs\n      ,sum(cq.query_execution_secs) as total_query_execution_secs\n\t  ,avg(cq.total_execution_secs) as avg_execution_secs\n      ,sum(cq.total_execution_secs) as total_execution_secs\n      ,count(cq.query) as query_count\n      ,sum(cq.unique_transaction) as total_unique_transaction\n      ,sum(cq.total_usage_consumer_count) as total_usage_consumer_count\n      ,sum(cq.request_error_count) as total_request_error_count \n  from consumer_query cq\ngroup by 1,2,3\n)\n,consumer_query_request_percentile AS (\nSELECT cq.request_date\n      ,cq.dbname\n      ,cq.db_username\n\t  ,percentile_cont(0.8) within GROUP ( ORDER BY request_duration_secs) AS p80_request_sec\n\t  ,percentile_cont(0.9) within GROUP ( ORDER BY request_duration_secs) AS p90_request_sec\n\t  ,percentile_cont(0.99) within GROUP ( ORDER BY request_duration_secs) AS p99_request_sec\n  from consumer_query cq\ngroup by 1,2,3\n)\nselect cqa.request_date\n      ,cqa.dbname\n      ,cqa.db_username\n      ,cqa.query_count\n\t  ,cqa.avg_query_execution_secs\n      ,cqa.total_query_execution_secs\n\t  ,cqa.avg_execution_secs\n      ,cqa.total_execution_secs\n\t  ,cqa.avg_request_duration_secs\n\t  ,cqrp.p80_request_sec\n\t  ,cqrp.p90_request_sec\n\t  ,cqrp.p99_request_sec\n      ,cqa.total_request_duration_secs\n\t  ,cqa.avg_request_interval_secs\n      ,cqa.total_request_interval_secs\t  \n      ,cqa.total_unique_transaction\n      ,cqa.total_usage_consumer_count\n      ,cqa.total_request_error_count\n  from consumer_query_aggregate cqa\n  inner join consumer_query_request_percentile cqrp on (cqa.request_date = cqrp.request_date and cqa.dbname = cqrp.dbname and cqa.db_username = cqrp.db_username)\norder by 1,2,3;"
    },
    "ATOWorkerActions": {
        "SQL": "WITH latest_worker_action AS\n(\n  SELECT table_id,\n         TYPE,\n         trim(status) as status,\n         eventtime,\n         ROW_NUMBER() OVER (PARTITION BY table_id,TYPE ORDER BY eventtime DESC) AS rnum\n  FROM svl_auto_worker_action w\n)\nSELECT trim(t.database_name) AS dbname,\n       t.schema_name AS namespace,\n       t.table_name,\n       w.type,\n       w.status AS latest_status,\n       w.eventtime\nFROM latest_worker_action w\n  INNER JOIN (SELECT DISTINCT(stv_tbl_perm.id) AS table_id\n                    ,TRIM(pg_database.datname) AS database_name\n                    ,TRIM(pg_namespace.nspname) AS schema_name\n                    ,TRIM(relname) AS table_name\n                FROM stv_tbl_perm\n              INNER JOIN pg_database on pg_database.oid = stv_tbl_perm.db_id\n              INNER JOIN pg_class on pg_class.oid = stv_tbl_perm.id\n              INNER JOIN pg_namespace on pg_namespace.oid = pg_class.relnamespace\n               WHERE schema_name NOT IN ('pg_internal', 'pg_catalog','pg_automv')) t\n          ON (t.table_id = w.table_id AND w.rnum = 1)\nORDER BY 1,2,3,4;"
    },
    "WorkloadEvaluation": {
        "SQL": "WITH hour_list AS\n(\n  SELECT DATE_TRUNC('m',starttime) start_hour,\n         dateadd('m',1,start_hour) AS end_hour\n  FROM stl_query q\n  WHERE starttime \u003E= (getdate() -7)\n  GROUP BY 1\n),\nscan_sum AS\n(\n  SELECT query,\n         segment,\n         SUM(bytes) AS bytes\n  FROM stl_scan\n  WHERE userid \u003E 1\n  GROUP BY query,\n           segment\n),\nscan_list AS\n(\n  SELECT query,\n         MAX(bytes) AS max_scan_bytes\n  FROM scan_sum\n  GROUP BY query\n),\nquery_list AS\n(\n  SELECT w.query,\n         exec_start_time,\n         exec_end_time,\n         ROUND(total_exec_time / 1000 / 1000.0,3) AS exec_sec,\n         max_scan_bytes,\n         CASE\n           WHEN max_scan_bytes \u003C 100000000 THEN 'small'\n           WHEN max_scan_bytes BETWEEN 100000000 AND 500000000000 THEN 'medium'\n           WHEN max_scan_bytes \u003E 500000000000 THEN 'large'\n         END AS size_type\n  FROM stl_wlm_query w,\n       scan_list sc\n  WHERE sc.query = w.query\n),\nworkload_exec_seconds  AS\n(\nselect \ncount(*) as query_cnt, \nSUM(CASE WHEN size_type = 'small' THEN  exec_sec  ELSE 0 END) AS small_workload_exec_sec_sum,\nSUM(CASE WHEN size_type = 'medium' THEN  exec_sec  ELSE 0 END) AS medium_workload_exec_sec_sum,\nSUM(CASE WHEN size_type = 'large' THEN  exec_sec  ELSE 0 END) AS large_workload_exec_sec_sum,\n  \nAVG(CASE WHEN size_type = 'small' THEN  exec_sec  ELSE 0 END) AS small_workload_exec_sec_avg,\nAVG(CASE WHEN size_type = 'medium' THEN  exec_sec  ELSE 0 END) AS medium_workload_exec_sec_avg,\nAVG(CASE WHEN size_type = 'large' THEN  exec_sec  ELSE 0 END) AS large_workload_exec_sec_avg,\n  \nMAX(CASE WHEN size_type = 'small' THEN  exec_sec  ELSE 0 END) AS small_workload_exec_sec_max,\nMAX(CASE WHEN size_type = 'medium' THEN  exec_sec  ELSE 0 END) AS medium_workload_exec_sec_max,\nMAX(CASE WHEN size_type = 'large' THEN  exec_sec  ELSE 0 END) AS large_workload_exec_sec_max,\n  \n  MIN(CASE WHEN size_type = 'small' THEN  exec_sec  ELSE 0 END) AS small_workload_exec_sec_min,\nMIN(CASE WHEN size_type = 'medium' THEN  exec_sec  ELSE 0 END) AS medium_workload_exec_sec_min,\nMIN(CASE WHEN size_type = 'large' THEN  exec_sec  ELSE 0 END) AS large_workload_exec_sec_min,\n  \nAVG(CASE WHEN size_type = 'small' THEN  max_scan_bytes  ELSE 0 END) AS small_workload_max_scan_bytes_avg,\nAVG(CASE WHEN size_type = 'medium' THEN  max_scan_bytes  ELSE 0 END) AS medium_workload_max_scan_bytes_avg,\nAVG(CASE WHEN size_type = 'large' THEN  max_scan_bytes  ELSE 0 END) AS large_workload_max_scan_bytes_avg,\n\n  (small_workload_exec_sec_sum+medium_workload_exec_sec_sum+large_workload_exec_sec_sum) as total_workload_exec_sec_sum,\nsmall_workload_exec_sec_sum/(total_workload_exec_sec_sum*1.00) as Small_workload_perc,\nmedium_workload_exec_sec_sum/(total_workload_exec_sec_sum*1.00) as Medium_workload_perc,\nlarge_workload_exec_sec_sum/(total_workload_exec_sec_sum*1.00) as Large_workload_perc\nfrom query_list\n)\n,query_list_2 AS\n(\n  SELECT start_hour,\n         query,\n         size_type,\n         max_scan_bytes,\n         exec_sec,\n         exec_start_time,\n         exec_end_time\n  FROM hour_list h,\n       query_list q\n  WHERE exec_start_time BETWEEN start_hour AND end_hour\n  OR    exec_end_time BETWEEN start_hour AND end_hour\n  OR    (exec_start_time \u003C start_hour AND exec_end_time \u003E end_hour)\n)\n\n,hour_list_agg AS\n(\n  SELECT start_hour,\n         SUM(CASE WHEN size_type = 'small' THEN 1 ELSE 0 END) AS small_query_cnt,\n         SUM(CASE WHEN size_type = 'medium' THEN 1 ELSE 0 END) AS medium_query_cnt,\n         SUM(CASE WHEN size_type = 'large' THEN 1 ELSE 0 END) AS large_query_cnt,\n         COUNT(*) AS tot_query_cnt\n  FROM query_list_2\n  GROUP BY start_hour\n) \n,utilization_perc AS\n(\nSELECT trunc(start_hour) AS sample_date,\n       ROUND(100*SUM(CASE WHEN tot_query_cnt \u003E 0 THEN 1 ELSE 0 END) / 1440.0,1) AS all_query_activite_perc,\n       ROUND(100*SUM(CASE WHEN small_query_cnt \u003E 0 THEN 1 ELSE 0 END) / 1440.0,1) AS small_query_activite_perc,\n       ROUND(100*SUM(CASE WHEN medium_query_cnt \u003E 0 THEN 1 ELSE 0 END) / 1440.0,1) AS medium_query_activite_perc,\n       ROUND(100*SUM(CASE WHEN large_query_cnt \u003E 0 THEN 1 ELSE 0 END) / 1440.0,1) AS large_query_activite_perc,\n       MIN(start_hour) AS start_hour,\n       MAX(start_hour) AS end_hour\nFROM hour_list_agg\nGROUP BY 1\n)\n\n,activity_perc as \n(\nSelect avg(small_query_activite_perc) AS AVG_small_query_activity_perc, \navg(medium_query_activite_perc) AS AVG_medium_query_activity_perc,\navg(large_query_activite_perc) AS AVG_large_query_activity_perc\nFROM utilization_perc\n)\n\n,mincount AS\n(\nSELECT trunc(start_hour) AS sample_date,\n       SUM(CASE WHEN tot_query_cnt \u003E 0 THEN 1 ELSE 0 END) AS tot_query_minute,\n       SUM(CASE WHEN small_query_cnt \u003E 0 THEN 1 ELSE 0 END) AS small_query_minute,\n       SUM(CASE WHEN medium_query_cnt \u003E 0 THEN 1 ELSE 0 END) AS medium_query_minute,\n       SUM(CASE WHEN large_query_cnt \u003E 0 THEN 1 ELSE 0 END) AS large_query_minute,\n       MIN(start_hour) AS start_hour,\n       MAX(start_hour) AS end_hour\nFROM hour_list_agg\nGROUP BY 1\n),avgmincount AS\n(\nSelect avg(small_query_minute) avg_small_query_minute, avg(medium_query_minute) avg_medium_query_minute, avg(large_query_minute) avg_large_query_minute\n  from mincount\n)\n,final_output AS \n(\nSelect   small_workload_perc , medium_workload_perc,    large_workload_perc,    \n  avg_small_query_activity_perc,    avg_medium_query_activity_perc,    avg_large_query_activity_perc,    \n  avg_small_query_minute,    avg_medium_query_minute,    avg_large_query_minute,\n  \n  small_workload_exec_sec_avg, medium_workload_exec_sec_avg, large_workload_exec_sec_avg,\n  small_workload_exec_sec_max, medium_workload_exec_sec_max, large_workload_exec_sec_max,\n  small_workload_exec_sec_min, medium_workload_exec_sec_min, large_workload_exec_sec_min,\n   total_query_cnt, total_small_query_cnt, \n  total_medium_query_cnt,total_large_query_cnt, \n  small_workload_max_scan_bytes_avg, \n  medium_workload_max_scan_bytes_avg, \n  large_workload_max_scan_bytes_avg\nfrom activity_perc a, avgmincount b, workload_exec_seconds c, (  select count(*) as total_query_cnt, sum(case when size_type = 'small' then 1 else 0 end) as  total_small_query_cnt, \n                                                              sum(case when size_type = 'medium' then 1 else 0 end) as  total_medium_query_cnt, \n                                                              sum(case when size_type = 'large' then 1 else 0 end) as  total_large_query_cnt\n                                                              from query_list )  d\nwhere 1=1\n\n)\nselect workloadtype, (perc_of_total_workload*100.00) as perc_of_total_workload, perc_duration_in_day, Total_query_minutes_in_day \n,workload_exec_sec_avg, workload_exec_sec_min, workload_exec_sec_max,query_cnt,scan_bytes_avg\nfrom\n(\nselect \n'Small' as workloadtype,\nsmall_workload_perc as perc_of_total_workload,\navg_small_query_activity_perc as perc_duration_in_day,\navg_small_query_minute as Total_query_minutes_in_day, \n small_workload_exec_sec_avg as  workload_exec_sec_avg,\n  small_workload_exec_sec_max as  workload_exec_sec_max, \n   small_workload_exec_sec_min as  workload_exec_sec_min,\n total_small_query_cnt as query_cnt, \n  small_workload_max_scan_bytes_avg as scan_bytes_avg,\n 1 as id\nfrom final_output\nunion\nselect \n'Meduim' as workloadtype,\nmedium_workload_perc as perc_of_total_workload,\navg_medium_query_activity_perc as perc_duration_in_day,\navg_medium_query_minute as Total_query_minutes_in_day ,\n  medium_workload_exec_sec_avg as  workload_exec_sec_avg,\n    medium_workload_exec_sec_max as  workload_exec_sec_max, \n   medium_workload_exec_sec_min as  workload_exec_sec_min,\n total_medium_query_cnt as query_cnt, \n  medium_workload_max_scan_bytes_avg as scan_bytes_avg,\n  2 as id\nfrom final_output\nunion\nselect \n'Large' as workloadtype,\nlarge_workload_perc as perc_of_total_workload,\navg_large_query_activity_perc as perc_duration_in_day,\navg_large_query_minute as Total_query_minutes_in_day, \n  large_workload_exec_sec_avg as  workload_exec_sec_avg,\n   large_workload_exec_sec_max as  workload_exec_sec_max, \n   large_workload_exec_sec_min as  workload_exec_sec_min,\n total_large_query_cnt as query_cnt, \n  large_workload_max_scan_bytes_avg as scan_bytes_avg,\n  3 as id\n from final_output\n  ) a order by id asc;",
        "Signals": [
            {
                "Signal": "Evaluate Workload for Serverless. Cluster is busy less than 75% of the time in a day.",
                "Criteria": "(select sum(total_query_minutes_in_day)/1440 from WorkloadEvaluation)*100 \u003C 75",
                "PopulationCriteria": "",
                "Recommendation": [
                    "35"
                ]
            }
        ]
    }
}